# Environment Variables
LLM_STUDIO_API_KEY=lmstudio
LLM_STUDIO_BASE_URL=http://localhost:1234/v1

# Model Configuration
# IMPORTANT: Use a Vision-Language Model (VLM) for image+text processing
# Recommended VLM models:
# - qwen2-vl-2b-instruct (recommended - small, fast, good quality)
# - qwen2-vl-7b-instruct (better quality, requires more VRAM)
# - llava-v1.6-mistral-7b (alternative option)
# - minicpm-v-2_6-gguf (good balance)
# Download from LM Studio: Search for "qwen2-vl" or "llava" in the model browser

LOCAL_LLM_MODEL=qwen3-vl-2b-instruct
EMBEDDING_MODEL=text-embedding-paraphrase-multilingual-mpnet-base-v2/paraphrase-multilingual-mpnet-base-v2-q8_0.gguf

# Vision Model (only used for captioning if LLM is not VLM)
# This can be disabled if using a VLM in LM Studio
VISION_MODEL=qwen3-vl-2b-instruct

# Audio Configuration
STT_MODEL=base
STT_LANGUAGE=en
TTS_MODEL=en_US-lessac-medium
AUDIO_SAMPLE_RATE=16000
PIPER_BINARY=C:/piper/piper.exe
PIPER_MODEL_PATH=C:/piper/models/en_US-lessac-high.onnx
PIPER_CONFIG_PATH=C:/piper/models/en_US-lessac-high.onnx.json
PIPER_SPEAKER_ID=

# Vector Store
CHROMA_PERSIST_DIR=./chroma_db
COLLECTION_NAME=multimodal_docs

# Agent Configuration
MAX_ITERATIONS=10
AGENT_VERBOSE=True
MAX_IMAGE_CONTEXT=2

# Application
APP_TITLE=Multimodal Vox Agent AI
UPLOAD_DIR=./uploads
TEMP_DIR=./temp
API_BASE_URL=http://127.0.0.1:8000
